\section{Literature review\label{sec:literature_review}}
% In the training of artificial neural networks for supervised learning problems, training data consisting of features (input) and labels (target output) is fed through the network. For each instance of training data, the output of the network generated on the basis of the features is compared to the label / target output.

\subsection{Federated learning}
Federated learning (FL) was introduced by Google in 2017 \citep{mcmahan2017communication}. In FL, different clients, called the \emph{federation}, jointly train an ML model. A central server coordinates the process. The big difference to the classical training of a neural network is that FL allows for ``the decoupling of model training from the need for direct access to the raw training data'' \citep{konevcny2016federated}. This means that while all clients in the federation take part in the training of the model, their data stays local and does not have to be transferred to other clients or a central server.

In practice, FL is often realized using \emph{FederatedAveraging} (FedAvg) \citep{mcmahan2017communication, li2020federated}, ``which combines local stochastic gradient descent (SGD) on each client with a server that performs model averaging'' \citep{mcmahan2017communication}. The server, a central node, coordinates the training. During each epoch, the weights of the local models (at each client) are updated based on the local data. Then, the updated weights are sent to the server, which averages over all of them weighted by the number of training data of each respective client. This can be done every epoch or less frequently. Finally, the server sends the averaged weights back to the clients, and the training continues. This iterative training takes place until convergence or a certain stopping criterion is reached \citep{mcmahan2017communication}, just like in the classical training of neural networks.

\citet{mcmahan2017communication} relate to the optimization problem of FL as \emph{federated optimization} to underline the differences to conventional distributed optimization approaches. In FL, key properties of the optimization/learning problem are that the data is non-IID, unbalanced, and massively distributed and that the communication is limited \citep{mcmahan2017communication, konevcny2016federated}, which is in strong contrast to a classical distributed optimization problem. The two latter points are more prominent in classical FL settings, such as the mobile device setting explained in section \ref{sec:introduction}, and less relevant in our SME context. In our case, however, data can be non-IID, meaning that the underlying distributions of the data of the various SMEs (clients) can vary strongly, and the data can be unbalanced in the sense that some SMEs (clients) have more data than others.

Several criteria regarding the learning problem have to be met so that FL is beneficial compared to only training one model per client. FL only makes sense if, firstly, more data leads to better performance. Secondly, the models of the nodes should be meaningfully combinable. Thirdly, the nodes must be able to execute a training step, not only a prediction step.

\citet{yang2019federated} introduce a categorization regarding the distribution characteristics of the data:
\begin{itemize}
    \item \emph{Horizontal Federated Learning}
    \item \emph{Vertical Federated Learning}
    \item \emph{Federated Transfer Learning}
\end{itemize}
Firstly, in \emph{horizontal FL}, the datasets have the same feature and label space but differ regarding their sample space. An example thereof would be two banks in different regions that both want to jointly create a credit scoring model without exchanging sensitive client data. The banks collect the same data on their clients (features and labels) but have different clients (samples). The introduced mobile device use case by Google \citep{mcmahan2017communication} also belongs to this category. Secondly, in \emph{vertical FL}, the datasets share the same sample space but differ regarding their feature and label space. An example thereof could be two companies having the same clients (samples) but offering different services, resulting in different features and labels. Finally, in \emph{federated transfer learning} the datasets differ in sample, feature, and label space which requires transfer learning techniques. This thesis is on horizontal FL in the SME context, meaning again that the SMEs participating in the federation have datasets with the same feature and label space but different sample spaces. A detailed description of the dataset used can be found in section \ref{sec:methodology_dataset}.

\subsection{Performance in the context of federated learning\label{sec:literature_performance}}
Clearly, model performance is a relevant dimension in evaluating FL. Since FL comes with increased efforts in comparison to the classical training of a neural network, applying FL is only justified if it leads to a better performance of the resulting model and hence, to a value-added for the clients. A special case is when the amount of data per client would not allow for the training of individual models and when sharing the data is not viable because of privacy issues. In this case, FL makes model training possible at all and hence, is justified if a sufficient value-adding performance level is reached.

In lots of cases, such as in the mobile device setting, the performance of the FL model is measured using problem-adequate metrics such as the accuracy over time, the number of communication rounds, or other parameters, compared for various model architectures \citep{mcmahan2017communication, sattler2019robust, yang2019federated}. \citet{konevcny2016federated} describe a trade-off between the number of communication rounds and performance over time as often a round of communication is by far more time-consuming than a single learning step.

Generally, the performance that can be reached (or reached after a specific training time) varies due to several factors such as the clients' computation and network speed, the computational complexity per sample, and other general model and FL-related parameters \citep{bonawitz2019towards}.

\citet{caldas2018leaf} provide implementations for several metrics for benchmarking FL algorithms, such as metrics that measure the distribution of the performance of the FL model on the client datasets. Moreover, they offer the possibility to weigh the importance of clients or single data points in the calculation of the metrics.

\subsection{Privacy in the context of federated learning\label{sec:literature_privacy}}
In FL, ``the decoupling of model training from the need for direct access to the raw training data'' \citep{konevcny2016federated} leads to a major advantage in comparison to classical centralized ML \citep{mcmahan2017communication}, since no data is shared between the clients. Still, information is exchanged to a certain extent, namely, the weights of the individual clients are sent to the central node. The weight updates result from the clients' local gradients, which in turn result from the clients' data. Hence, these weights, to a certain extent, contain information on the clients' data. This exchange provides a point of vulnerability concerning privacy attacks \citep{yang2019federated}.

Even when disregarding external attacks, internal attacks from other clients (``malicious client(s)'') or the server (``malicious server'') cannot be ruled out \citep{enthoven2021overview} and the distributed nature of FL provides opportunities for attacks and complicates handling these \citep{sun2019can}. However, ``the strength of privacy benefit depends on the content of the updates'' \citep{mcmahan2017communication}.

Several potential adversarial attacks are mentioned in the literature, though most might not be realistic in real-world use cases. Generally, there are two main goals of adversarial attacks on FL models. Firstly, to extract private information about the clients' data, and secondly, to corrupt the model, e.g., forcing misclassification \citep{enthoven2021overview}. \citet{enthoven2021overview} describe several attacks, which we will discuss in detail in section \ref{sec:privacy_analysis} and assess their relevance for SME use cases.

\citet{sun2019can} describe that, in the case of no defense measures, the success of attacks mainly depends on two factors. Firstly, the number of opponents, and secondly, the complexity of the learning task. Several publications describe techniques for improving privacy in FL \citep{yang2019federated, naseri2020toward, sun2019can}, such as \emph{secure multiparty computation (SMC)}, \emph{homomorphic encryption}, or \emph{differential privacy}. The latter could be used to hide the clients' contributions and hence, to increase the protection of the clients' data \citep{yang2019federated}. \citet{sun2019can} describe that implementing even a weak version of \emph{differential privacy}, could soften the attack without harming the model's performance.

\subsection{Complexity in the context of federated learning\label{sec:literature_complexity}}
In comparison to centralized optimization, the distributed nature of FL requires additional communication between the clients and the central node, resulting in increased complexity of the whole setting \citep{mcmahan2017communication}. Hence, communication can be a key bottleneck of FL. Especially in a network with a large number of clients, the communication time can even dominate the time needed for the local computations on, e.g., the mobile devices \citep{li2020federated}. Consequently, measuring communication time is an important factor to compare distributed algorithms regarding efficiency and hence, to decide which algorithms are best suited for the given problem \citep{konevcny2016federated}.

Another aspect of complexity is computation. \citet{mcmahan2017communication} describe three key parameters that control the amount of computation, namely ``the fraction of clients that perform computation on each round'', ``the number of training passes each client makes over its local dataset on each round'', and ``the local minibatch size used for the client updates''. The complexity can be measured, e.g., by counting the number of communications rounds \citep{mcmahan2017communication} or the number of iterations and communicated bits \citep{konevcny2016federated, sattler2019robust}, until a certain target accuracy is reached. \citet{caldas2018leaf} provide implementations of metrics that account, e.g., for the amount of computing resources or communicated bits.

To reduce complexity, generally, two aspects relating to communication are of great importance. Firstly, the total number of communication rounds, and secondly, the size of the updates \citep{li2020federated}. Several methods and approaches exist to decrease complexity which in the vast majority of the literature refers to reducing the amount of communication. For example, \citet{smith2017federated} present an optimization method, \emph{MOCHA}, to speed up the training of multi-task ML models in a distributed fashion. Additionally, \citet{sattler2019robust} present a compression framework (\emph{sparse ternary compression (STC)}) which relies on high-frequent low-volume communication instead of low-frequent high-volume as in \emph{FederatedAveraging}.
